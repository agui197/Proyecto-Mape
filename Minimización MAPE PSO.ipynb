{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Notebook para implementar la regresión con minimización del MAPE y la optimización de hyperparámetros por medio de PSO.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar librerías que se usarán en el notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics.pairwise import (linear_kernel,rbf_kernel)\n",
    "import cvxpy as cp #https://www.cvxpy.org/\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pyswarm import pso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones creadas por el usuario que son necesarias para la ejecución de la optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% Funcion MAPE\n",
    "def mean_absolute_percentage_error(y_true,y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "#% Generate X data points\n",
    "def genX(lmin=0,lmax=20,npoints=29):\n",
    "    x1 = np.linspace(lmin,lmax,npoints)\n",
    "    x2 = np.linspace(lmin,lmax,npoints)\n",
    "    X1,X2 = np.meshgrid(x1,x2)\n",
    "    x1m = np.ravel(X1.T)\n",
    "    x2m = np.ravel(X2.T)\n",
    "    Xm = np.c_[x1m,x2m]\n",
    "    return Xm\n",
    "\n",
    "\n",
    "#% Test function 1 (Hyperplane)\n",
    "def testfunction1(X,noise=False):\n",
    "    # Modelo: Y = 2*X1+3*X2+40\n",
    "    X1 = X[:,0]\n",
    "    X2 = X[:,1]\n",
    "    if noise:\n",
    "        Y = 2*X1+3*X2+40+(5*np.random.rand(X.shape[0])-2.5)\n",
    "    else:\n",
    "        Y = 2*X1+3*X2+40\n",
    "    \n",
    "    y = np.ravel(Y.T)\n",
    "    return y\n",
    "\n",
    "#% Test function 2\n",
    "def testfunction2(X,noise=False):\n",
    "    # Modelo: Y = 500+(x1^2-x2^2)*sin(0.5*x1)+10\n",
    "    X1 = X[:,0]\n",
    "    X2 = X[:,1]\n",
    "    X1 = X1-(max(X1)+min(X1))/2\n",
    "    X2 = X2-(max(X2)+min(X2))/2\n",
    "    if noise:\n",
    "        Y = 100+(X1**2-X2**2)*np.sin(0.5*X1)+(5*np.random.rand(X.shape[0])-2.5)\n",
    "    else:\n",
    "        Y = 100+(X1**2-X2**2)*np.sin(0.5*X1)\n",
    "    \n",
    "    y = np.ravel(Y.T)\n",
    "    return y\n",
    "\n",
    "#% Test function 3\n",
    "def testfunction3(X,noise=False):\n",
    "    # Modelo: Y = sin(sqrt(x1^2+x2^2))/sqrt(x1^2+x2^2)+10\n",
    "    X1 = X[:,0]\n",
    "    X2 = X[:,1]\n",
    "    X1 = X1-(max(X1)+min(X1))/2\n",
    "    X2 = X2-(max(X2)+min(X2))/2\n",
    "    den = np.sqrt(X1**2+X2**2)\n",
    "    den[den==0]=0.001\n",
    "    if noise:\n",
    "        Y = 10+np.sin(np.sqrt(X1**2+X2**2))/den+(0.5*np.random.rand(X.shape[0])-0.25)\n",
    "    else:\n",
    "        Y = 10+np.sin(np.sqrt(X1**2+X2**2))/den\n",
    "    \n",
    "    y = np.ravel(Y.T)\n",
    "    return y\n",
    "\n",
    "#% Test function 4\n",
    "def testfunction4(X,noise=False):\n",
    "    # Modelo: Y = x1^2+x2^2-np.cos(2*x1)-np.cos(2*x2)+10\n",
    "    X1 = X[:,0]\n",
    "    X2 = X[:,1]\n",
    "    X1 = X1-(max(X1)+min(X1))/2\n",
    "    X2 = X2-(max(X2)+min(X2))/2\n",
    "    if noise:\n",
    "        Y = 10+X1**2+X2**2-10*np.cos(2*X1)-10*np.cos(2*X2)+(5*np.random.rand(X.shape[0])-2.5)\n",
    "    else:\n",
    "        Y = 10+X1**2+X2**2-10*np.cos(2*X1)-10*np.cos(2*X2)\n",
    "    \n",
    "    y = np.ravel(Y.T)\n",
    "    return y\n",
    "\n",
    "#% Custom kernel function\n",
    "def custom_kernel(X1,X2,kernel='linear',gamma=None,lck=1):\n",
    "    # Kernel matrix\n",
    "    if kernel == 'linear':\n",
    "        K = linear_kernel(X1,X2)\n",
    "    elif kernel == 'rbf':\n",
    "        K = rbf_kernel(X1,X2,gamma=gamma)\n",
    "    elif kernel == 'linrbf':\n",
    "        K = lck*linear_kernel(X1,X2)+(1-lck)*rbf_kernel(X1,X2,gamma=gamma)\n",
    "    return K\n",
    "\n",
    "#% Simulacion del modelo de regresion\n",
    "def sim_modelo(X,params):\n",
    "    K_sv = custom_kernel(params[0],X,kernel=params[3],gamma=params[4],lck=params[5])\n",
    "    y = np.dot(params[1],K_sv)+params[2]\n",
    "    return y\n",
    "\n",
    "#% Funcion SVR_E\n",
    "def SVR_E(X,y,epsilon=0.01,c=10,kernel='linear',gamma=None,lck=1):\n",
    "    # epsilon = 0.01 # margin max\n",
    "    # c = 10 # alphas constraint\n",
    "    # kernel = 'linear' # kernel type, options: ('linear','rbf','linrbf')\n",
    "    # gamma = None # gamma parameter for rbf-kernel and linrbf-kernel\n",
    "    # lck = 1 # constant for kernel linear combination, 0<=lck<=1\n",
    "    \n",
    "    umbral = 1E-5 # umbral to define a vector support\n",
    "    \n",
    "    nsamples,nfeatures = np.shape(X)\n",
    "    onev = np.ones((nsamples,1))\n",
    "    \n",
    "    # Kernel matrix\n",
    "    K = custom_kernel(Xm,Xm,kernel=kernel,gamma=gamma,lck=lck)\n",
    "\n",
    "    # Optimization E-regression\n",
    "    alpha1 = cp.Variable((nsamples,1))\n",
    "    alpha2 = cp.Variable((nsamples,1))\n",
    "    \n",
    "    Ev = onev*epsilon\n",
    "    objective = cp.Minimize((1/2)*cp.quad_form(alpha1-alpha2, K) + Ev.T @ (alpha1+alpha2) - y.T @ (alpha1 - alpha2))\n",
    "    \n",
    "    # Constrains in matrix form\n",
    "    G = np.float64(np.concatenate((np.identity(nsamples),-np.identity(nsamples))))\n",
    "    h = np.float64(np.concatenate((c*np.ones((nsamples,1)),np.zeros((nsamples,1)))))\n",
    "    \n",
    "    constraints = [onev.T @ (alpha1-alpha2) == 0, G @ alpha1 <= h, G @ alpha2 <= h]\n",
    "    \n",
    "    # The optimal objective value is returned by `prob.solve()`.\n",
    "    prob = cp.Problem(objective,constraints)\n",
    "    result = prob.solve()\n",
    "    \n",
    "    alpha1 = np.array(alpha1.value)\n",
    "    alpha2 = np.array(alpha2.value)\n",
    "    alphas = alpha1-alpha2\n",
    "    indx = abs(alphas) > umbral\n",
    "    alpha_sv = alphas[indx]\n",
    "    x_sv = X[indx[:,0],:]\n",
    "    y_sv = y[indx[:,0]]\n",
    "    \n",
    "    \n",
    "    # Coef0 obtention\n",
    "    b = np.mean(y_sv-np.dot(alpha_sv,custom_kernel(x_sv,x_sv,kernel=kernel,gamma=gamma,lck=lck)))\n",
    "    \n",
    "    return x_sv,alpha_sv,b,kernel,gamma,lck\n",
    "\n",
    "#% Optimization E-regression MAPE usando cvxpy\n",
    "def SVR_E_MAPE(X,y,epsilon=0.01,c=10,kernel='rbf',gamma=None,lck=1):\n",
    "    # epsilon = 0.01 # margin max\n",
    "    # c = 10 # alphas constraint\n",
    "    # kernel = 'linear' # kernel type, options: ('linear','rbf','linrbf')\n",
    "    # gamma = None # gamma parameter for rbf-kernel and linrbf-kernel\n",
    "    # lck = 1 # constant for kernel linear combination, 0<=lck<=1\n",
    "    umbral = 1E-5 # umbral to define a vector support\n",
    "    \n",
    "    nsamples,nfeatures = np.shape(X)\n",
    "    onev = np.ones((nsamples,1))\n",
    "    \n",
    "    # Kernel matrix\n",
    "    K = custom_kernel(Xm,Xm,kernel=kernel,gamma=gamma,lck=lck)\n",
    "    \n",
    "    # Optimization E-regression with MAPE\n",
    "    alpha1 = cp.Variable((nsamples,1))\n",
    "    alpha2 = cp.Variable((nsamples,1))\n",
    "    \n",
    "    Ev = np.reshape(y,(nsamples,1))*epsilon\n",
    "    objective = cp.Minimize((1/2)*cp.quad_form(alpha1-alpha2, K) + Ev.T @ (alpha1+alpha2) - y.T @ (alpha1 - alpha2))\n",
    "    \n",
    "    # Constrains in matrix form\n",
    "    G = np.float64(np.concatenate((np.identity(nsamples),-np.identity(nsamples))))\n",
    "    h=np.float64(np.concatenate((c/np.reshape(y,(nsamples,1)),np.zeros((nsamples,1)))))\n",
    "    constraints = [onev.T @ (alpha1-alpha2) == 0, G @ alpha1 <= h, G @ alpha2 <= h]\n",
    "    \n",
    "    # The optimal objective value is returned by `prob.solve()`.\n",
    "    prob = cp.Problem(objective,constraints)\n",
    "    result = prob.solve()\n",
    "    \n",
    "    \n",
    "    alpha1 = np.array(alpha1.value)\n",
    "    alpha2 = np.array(alpha2.value)\n",
    "    alphas = alpha1-alpha2\n",
    "    indx = abs(alphas) > umbral\n",
    "    alpha_sv = alphas[indx]\n",
    "    x_sv = X[indx[:,0],:]\n",
    "    y_sv = y[indx[:,0]]\n",
    "    \n",
    "    # Coef0 obtention\n",
    "    b = np.mean(y_sv-np.dot(alpha_sv,custom_kernel(x_sv,x_sv,kernel=kernel,gamma=gamma,lck=lck)))\n",
    "    \n",
    "    return x_sv,alpha_sv,b,kernel,gamma,lck\n",
    "\n",
    "#% Optimization classic v formulation E-regression usando cvxpy\n",
    "def SVR_vE(X,y,epsilon=0.01,c=10,v=1,kernel='linear',gamma=None,lck=1):\n",
    "    #    epsilon = 0.01 # margin max\n",
    "    #    v = 1 # New term\n",
    "    #    c = 10 # alphas constraint\n",
    "    # kernel = 'linear' # kernel type, options: ('linear','rbf','linrbf')\n",
    "    # gamma = None # gamma parameter for rbf-kernel and linrbf-kernel\n",
    "    # lck = 1 # constant for kernel linear combination, 0<=lck<=1\n",
    "    \n",
    "    umbral = 1E-5 # vector support \n",
    "    nsamples,nfeatures = np.shape(X)\n",
    "    onev = np.ones((nsamples,1))\n",
    "    \n",
    "    # Kernel matrix\n",
    "    K = custom_kernel(Xm,Xm,kernel=kernel,gamma=gamma,lck=lck)\n",
    "    \n",
    "    # Optimization formulation vE-regression \n",
    "    alpha1 = cp.Variable((nsamples,1))\n",
    "    alpha2 = cp.Variable((nsamples,1))\n",
    "    \n",
    "    objective = cp.Minimize((1/2)*cp.quad_form(alpha1-alpha2, K) - y.T @ (alpha1 - alpha2))\n",
    "    \n",
    "    # Restricciones forma matricial\n",
    "    G = np.float64(np.concatenate((np.identity(nsamples),-np.identity(nsamples))))\n",
    "    h = np.float64(np.concatenate((c*np.ones((nsamples,1)),np.zeros((nsamples,1)))))\n",
    "    \n",
    "    constraints = [onev.T @ (alpha1-alpha2) == 0,\n",
    "                   onev.T @ (alpha1+alpha2) == c*v,\n",
    "                   G @ alpha1 <= h,\n",
    "                   G @ alpha2 <= h]\n",
    "    \n",
    "    # The optimal objective value is returned by `prob.solve()`.\n",
    "    prob = cp.Problem(objective,constraints)\n",
    "    result = prob.solve()\n",
    "    \n",
    "    alpha1 = np.array(alpha1.value)\n",
    "    alpha2 = np.array(alpha2.value)\n",
    "    alphas = alpha1-alpha2\n",
    "    indx = abs(alphas) > umbral\n",
    "    alpha_sv = alphas[indx]\n",
    "    x_sv = X[indx[:,0],:]\n",
    "    y_sv = y[indx[:,0]]\n",
    "    \n",
    "    # Coef0 obtention\n",
    "    b = np.mean(y_sv-np.dot(alpha_sv,custom_kernel(x_sv,x_sv,kernel=kernel,gamma=gamma,lck=lck)))\n",
    "    \n",
    "    return x_sv,alpha_sv,b,kernel,gamma,lck\n",
    "\n",
    "#% Optimization v formulation MAPE-regression usando cvxpy\n",
    "def SVR_vMAPE(X,y,epsilon=0.01,c=10,v=1,kernel='linear',gamma=None,lck=1):\n",
    "    #    epsilon = 0.01 # margin max\n",
    "    #    v = 1 # New term\n",
    "    #    c = 10 # alphas constraint\n",
    "    # kernel = 'linear' # kernel type, options: ('linear','rbf','linrbf')\n",
    "    # gamma = None # gamma parameter for rbf-kernel and linrbf-kernel\n",
    "    # lck = 1 # constant for kernel linear combination, 0<=lck<=1\n",
    "    \n",
    "    umbral = 1E-5 # vector support \n",
    "    nsamples,nfeatures = np.shape(X)\n",
    "    onev = np.ones((nsamples,1))\n",
    "    \n",
    "    # Kernel matrix\n",
    "    K = custom_kernel(Xm,Xm,kernel=kernel,gamma=gamma,lck=lck)\n",
    "    \n",
    "    # Optimization formulation vE-regression with MAPE\n",
    "    alpha1 = cp.Variable((nsamples,1))\n",
    "    alpha2 = cp.Variable((nsamples,1))\n",
    "    \n",
    "    objective = cp.Minimize((1/2)*cp.quad_form(alpha1-alpha2, K) - y.T @ (alpha1 - alpha2))\n",
    "    \n",
    "    # Restricciones forma matricial\n",
    "    G = np.float64(np.concatenate((np.identity(nsamples),-np.identity(nsamples))))\n",
    "    h=np.float64(np.concatenate((100*c/np.reshape(y,(nsamples,1)),np.zeros((nsamples,1)))))\n",
    "    constraints = [onev.T @ (alpha1-alpha2) == 0,\n",
    "                   (y/100).T @ (alpha1+alpha2) == c*v,\n",
    "                   G @ alpha1 <= h,\n",
    "                   G @ alpha2 <= h]\n",
    "    \n",
    "    # The optimal objective value is returned by `prob.solve()`.\n",
    "    prob = cp.Problem(objective,constraints)\n",
    "    result = prob.solve()\n",
    "    \n",
    "    alpha1 = np.array(alpha1.value)\n",
    "    alpha2 = np.array(alpha2.value)\n",
    "    alphas = alpha1-alpha2\n",
    "    indx = abs(alphas) > umbral\n",
    "    alpha_sv = alphas[indx]\n",
    "    x_sv = X[indx[:,0],:]\n",
    "    y_sv = y[indx[:,0]]\n",
    "    \n",
    "    # Coef0 obtention\n",
    "    b = np.mean(y_sv-np.dot(alpha_sv,custom_kernel(x_sv,x_sv,kernel=kernel,gamma=gamma,lck=lck)))\n",
    "    \n",
    "    return x_sv,alpha_sv,b,kernel,gamma,lck\n",
    "\n",
    "#% Funcion para optimizar parametros de formulacion SVR_E con pso\n",
    "def opt_SVR_E(x, *args):\n",
    "    epsilon,c,v,gamma,lck = x\n",
    "    Xm,y = args\n",
    "    try:\n",
    "        params_E = SVR_E(Xm,y,epsilon=epsilon,c=c,kernel='rbf',gamma=gamma,lck=lck)\n",
    "        y_Ereg = sim_modelo(Xm,params_E)\n",
    "        mape_ereg = mean_absolute_percentage_error(y,y_Ereg)\n",
    "    except:\n",
    "        mape_ereg = 1000000\n",
    "    return mape_ereg\n",
    "\n",
    "#% Funcion para optimizar parametros de formulacion SVR_E_MAPE con pso\n",
    "def opt_SVR_E_MAPE(x, *args):\n",
    "    epsilon,c,v,gamma,lck = x\n",
    "    Xm,y = args\n",
    "    try:\n",
    "        params_Emape = SVR_E_MAPE(Xm,y,epsilon=0.01,c=10,kernel='rbf',gamma=None,lck=1)\n",
    "        y_mape = sim_modelo(Xm,params_Emape)\n",
    "        mape_mape = mean_absolute_percentage_error(y,y_mape)\n",
    "    except:\n",
    "        mape_mape = 1000000\n",
    "    return mape_mape\n",
    "\n",
    "#% Funcion para optimizar parametros de formulacion SVR_vE con pso\n",
    "def opt_SVR_vE(x, *args):\n",
    "    epsilon,c,v,gamma,lck = x\n",
    "    Xm,y = args\n",
    "    try:\n",
    "        params_vE = SVR_vE(Xm,y,epsilon=0.01,c=10,v=1,kernel='rbf',gamma=None,lck=1)\n",
    "        y_vE = sim_modelo(Xm,params_vE)\n",
    "        mape_vE = mean_absolute_percentage_error(y,y_vE)\n",
    "    except:\n",
    "        mape_vE = 1000000\n",
    "    return mape_vE\n",
    "\n",
    "#% Funcion para optimizar parametros de formulacion SVR_vMAPE con pso\n",
    "def opt_SVR_vMAPE(x, *args):\n",
    "    epsilon,c,v,gamma,lck = x\n",
    "    Xm,y = args\n",
    "    try:\n",
    "        params_vmape = SVR_vMAPE(Xm,y,epsilon=0.01,c=10,v=1,kernel='rbf',gamma=None,lck=1)\n",
    "        y_vmape = sim_modelo(Xm,params_vmape)\n",
    "        mape_vmape = mean_absolute_percentage_error(y,y_vmape)\n",
    "    except:\n",
    "        mape_vmape = 1000000\n",
    "    return mape_vmape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generación de los datos de la funcion de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "lmin = 1\n",
    "lmax = 20\n",
    "n = 29\n",
    "Xm = genX(lmin=lmin,lmax=lmax,npoints=n)\n",
    "y = testfunction3(X=Xm,noise=False)\n",
    "#% Visualizar los datos\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(Xm[:,0], Xm[:,1], y, c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Optimización de los hyperparámetros para la formulación SVR_E*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (Xm,y)\n",
    "\n",
    "# Define the lower and upper bounds for H, d, t, respectively\n",
    "lb = [0, 0, 0,0,0]\n",
    "ub = [30, 10, 10,100,1]\n",
    "\n",
    "\n",
    "## optimization\n",
    "xopt_SVR_E, fopt_SVR_E = pso(opt_SVR_E, lb, ub, args=args)\n",
    "xopt_SVR_E\n",
    "fopt_SVR_E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Optimización de los hyperparámetros para la formulación SVR_E_MAPE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Optimization SVR_E_MAPE\n",
    "args = (Xm,y)\n",
    "\n",
    "# Define the lower and upper bounds for H, d, t, respectively\n",
    "lb = [0, 0, 0,0,0]\n",
    "ub = [30, 10, 10,100,1]\n",
    "\n",
    "## optimization\n",
    "xopt_SVR_E_MAPE, fopt_SVR_E_MAPE = pso(opt_SVR_E_MAPE, lb, ub, args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Optimización de los hyperparámetros para la formulación SVR_vE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Optimization SVR_vE\n",
    "args = (Xm,y)\n",
    "\n",
    "# Define the lower and upper bounds for H, d, t, respectively\n",
    "lb = [0, 0, 0,0,0]\n",
    "ub = [30, 10, 10,100,1]\n",
    "\n",
    "## optimization\n",
    "xopt_SVR_vE, fopt_SVR_vE = pso(opt_SVR_vE, lb, ub, args=args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Optimización de los hyperparámetros para la formulación SVR_vMAPE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Optimization SVR_vMAPE\n",
    "args = (Xm,y)\n",
    "\n",
    "# Define the lower and upper bounds for H, d, t, respectively\n",
    "lb = [0, 0, 0,0,0]\n",
    "ub = [30, 10, 10,100,1]\n",
    "\n",
    "## optimization\n",
    "xopt_SVR_vMAPE, fopt_SVR_vMAPE = pso(opt_SVR_vMAPE, lb, ub, args=args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
